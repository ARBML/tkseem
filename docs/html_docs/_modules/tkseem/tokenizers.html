

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>tkseem.tokenizers &mdash; tkseem  documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> tkseem
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tokenizers.html">Tokenizers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../demo.html">Demo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sentiment analysis.html">Sentiment Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../meter classification.html">Poetry Classification</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">tkseem</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>tkseem.tokenizers</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for tkseem.tokenizers</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">mmap</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">operator</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">sentencepiece</span> <span class="k">as</span> <span class="nn">spm</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span><span class="p">,</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">farasa.segmenter</span> <span class="kn">import</span> <span class="n">FarasaSegmenter</span>
<span class="kn">from</span> <span class="nn">.util</span> <span class="kn">import</span> <span class="n">clean_data</span><span class="p">,</span> <span class="n">normalize_data</span><span class="p">,</span> <span class="n">split_on_binary</span>


<div class="viewcode-block" id="BaseTokenizer"><a class="viewcode-back" href="../../api/tkseem.tokenizers.BaseTokenizer.html#tkseem.tokenizers.BaseTokenizer">[docs]</a><span class="k">class</span> <span class="nc">BaseTokenizer</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base Tokenizer that implements the basic functionalities of a tokenizer</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">unk_token</span><span class="o">=</span><span class="s2">&quot;&lt;UNK&gt;&quot;</span><span class="p">,</span>
        <span class="n">pad_token</span><span class="o">=</span><span class="s2">&quot;&lt;PAD&gt;&quot;</span><span class="p">,</span>
        <span class="n">segment</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">vocab_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
        <span class="n">segm_token</span><span class="o">=</span><span class="s2">&quot;+&quot;</span><span class="p">,</span>
        <span class="n">clean</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Constructor</span>

<span class="sd">        Args:</span>
<span class="sd">            unk_token (str, optional): reserved token for unknowns. Defaults to &quot;&lt;UNK&gt;&quot;.</span>
<span class="sd">            pad_token (str, optional): reserved token for padding. Defaults to &quot;&lt;PAD&gt;&quot;.</span>
<span class="sd">            segment (bool, optional): segment using farasa. Defaults to False.</span>
<span class="sd">            max_tokens (int, optional): max number of vocabulary. Defaults to 10000.</span>
<span class="sd">            segm_token (str, optional): reserved token for segmentation. Defaults to &#39;+&#39;.</span>
<span class="sd">            clean (bool, optional): remove tashkeel, english and special chars. Defaults to False.</span>
<span class="sd">            normalize (bool, optional): normalize chars. Defaults to False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">segm_token</span> <span class="o">=</span> <span class="n">segm_token</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unk_token</span> <span class="o">=</span> <span class="n">unk_token</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">pad_token</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">segment</span> <span class="o">=</span> <span class="n">segment</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clean</span> <span class="o">=</span> <span class="n">clean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span> <span class="o">=</span> <span class="n">normalize</span>

        <span class="c1"># relative path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rel_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)</span>
        <span class="n">norm_dict_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rel_path</span><span class="p">,</span> <span class="s1">&#39;dictionaries/normalization_dictionary.pl&#39;</span><span class="p">)</span>
        <span class="n">cach_dict_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rel_path</span><span class="p">,</span> <span class="s1">&#39;dictionaries/cached.pl&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_dict</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">norm_dict_path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cached</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">cach_dict_path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">segment</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Initializing Farasa&quot;</span><span class="p">)</span>
            <span class="c1"># suppress farasa stdout</span>
            <span class="c1"># WARNING: this is LINUX ONLY command!</span>
            <span class="n">old_stdout</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">devnull</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">segmenter</span> <span class="o">=</span> <span class="n">FarasaSegmenter</span><span class="p">(</span><span class="n">interactive</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="c1"># resume farasa stdout</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span> <span class="o">=</span> <span class="n">old_stdout</span>

<div class="viewcode-block" id="BaseTokenizer.process_data"><a class="viewcode-back" href="../../api/tkseem.tokenizers.BaseTokenizer.html#tkseem.tokenizers.BaseTokenizer.process_data">[docs]</a>    <span class="k">def</span> <span class="nf">process_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_path</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; </span>
<span class="sd">        Read, segment, clean, normalize and split</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): the directory of the data to read</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reading the data ...&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">corpus</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">segment</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Segmenting the data ...&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">corpus</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">segmenter</span><span class="o">.</span><span class="n">segment</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">corpus</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">corpus</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[+]&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">segm_token</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">corpus</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clean</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cleaning the data ...&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">corpus</span> <span class="o">=</span> <span class="n">clean_data</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">corpus</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Normalizing the data ...&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">corpus</span> <span class="o">=</span> <span class="n">normalize_data</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">corpus</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_dict</span><span class="p">)</span>

        <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;data/raw&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># self.train_text, self.valid_text, self.test_text = self._split_corpus()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_write_data</span><span class="p">(</span><span class="s2">&quot;data/raw/train.txt&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">corpus</span><span class="p">)</span>
        <span class="c1"># self._write_data(&quot;data/raw/valid.txt&quot;, self.valid_text)</span>
        <span class="c1"># self._write_data(&quot;data/raw/test.txt&quot;, self.test_text)</span>
        <span class="c1"># del self.train_text, self.valid_text, self.test_text</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">corpus</span></div>

    <span class="k">def</span> <span class="nf">_get_tokens_frequency_quickly</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_path</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the tokens frequency quickly using memory mapping</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): the directory of the data to read</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            Dict: frequency based dictionary   </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="s2">&quot;utf8&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="n">encoding</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">mmap</span><span class="o">.</span><span class="n">mmap</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">fileno</span><span class="p">(),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">access</span><span class="o">=</span><span class="n">mmap</span><span class="o">.</span><span class="n">ACCESS_READ</span><span class="p">)</span> <span class="k">as</span> <span class="n">m</span><span class="p">:</span>
                <span class="n">m</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">size_to_read</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e9</span><span class="p">)</span>
                <span class="n">freq</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">([])</span>
                <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">/</span> <span class="n">size_to_read</span><span class="p">))</span>
                <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">m</span><span class="o">.</span><span class="n">size</span><span class="p">():</span>
                    <span class="n">cur_txt</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">size_to_read</span><span class="p">)</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="n">size_to_read</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">cur_txt</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">encoding</span><span class="p">)</span>
                    <span class="k">except</span><span class="p">:</span>
                        <span class="n">cur_txt</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span> <span class="o">+</span> <span class="n">m</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">encoding</span><span class="p">)</span>
                        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">freq</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">cur_txt</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">))</span>
                    <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">freq</span>

    <span class="k">def</span> <span class="nf">_write_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Write the string data to a path</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): the directory of the data to read</span>
<span class="sd">        </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TOCHECK: I think this code will break if the path does not exist.</span>
        <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_split_corpus</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Split the data into train, valid and test</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple: train, valid, test</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">split_length</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">corpus</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
        <span class="n">trainval_text</span><span class="p">,</span> <span class="n">test_text</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">corpus</span><span class="p">[:</span><span class="n">split_length</span><span class="p">],</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">corpus</span><span class="p">[</span><span class="n">split_length</span><span class="p">:],</span>
        <span class="p">)</span>
        <span class="n">split_length</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainval_text</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
        <span class="n">train_text</span><span class="p">,</span> <span class="n">val_text</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">trainval_text</span><span class="p">[:</span><span class="n">split_length</span><span class="p">],</span>
            <span class="n">trainval_text</span><span class="p">[</span><span class="n">split_length</span><span class="p">:],</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">train_text</span><span class="p">,</span> <span class="n">val_text</span><span class="p">,</span> <span class="n">test_text</span>

    <span class="k">def</span> <span class="nf">_get_tokens_frequency</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_path</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get tokens frequency using a dictionary</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): file path to read</span>
<span class="sd">        Returns:</span>
<span class="sd">            dict : dict containing frequency</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">text</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">tokens_frequency</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
            <span class="n">tokens_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">tokens_frequency</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_split_word</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">,</span> <span class="n">number_of_subwords</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Split a word into a specific number of sub-words</span>

<span class="sd">        Args:</span>
<span class="sd">            word (str): word input</span>
<span class="sd">            number_of_subwords (int): number of subtokens to generate from the word </span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            list: list of subwords </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">number_of_subwords</span> <span class="o">&gt;</span> <span class="mi">0</span>

        <span class="k">def</span> <span class="nf">_split</span><span class="p">(</span><span class="n">_word</span><span class="p">,</span> <span class="n">_number_of_subwords</span><span class="p">):</span>
            <span class="n">groups</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="n">_number_of_subwords</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">groups</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="s2">&quot;##&quot;</span> <span class="o">+</span> <span class="n">_word</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">_word</span><span class="p">),</span> <span class="mi">1</span><span class="p">):</span>
                    <span class="n">groups</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                        <span class="p">[</span><span class="s2">&quot;##&quot;</span> <span class="o">+</span> <span class="n">_word</span><span class="p">[:</span><span class="n">i</span><span class="p">],</span> <span class="o">*</span><span class="n">group</span><span class="p">]</span>
                        <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">_split</span><span class="p">(</span><span class="n">_word</span><span class="p">[</span><span class="n">i</span><span class="p">:],</span> <span class="n">_number_of_subwords</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">group</span><span class="p">)</span> <span class="o">==</span> <span class="n">_number_of_subwords</span> <span class="o">-</span> <span class="mi">1</span>
                    <span class="p">)</span>
            <span class="k">return</span> <span class="n">groups</span>

        <span class="n">groups_of_subwords</span> <span class="o">=</span> <span class="n">_split</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">number_of_subwords</span><span class="p">)</span>
        <span class="n">out_groups</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">groups_of_subwords</span><span class="p">:</span>
            <span class="n">group</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;##&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="n">out_groups</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">group</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out_groups</span>

    <span class="k">def</span> <span class="nf">_split_word_cached</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">,</span> <span class="n">number_of_subwords</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Faster version of word splitting</span>

<span class="sd">        Args:</span>
<span class="sd">            word (word): word to be split</span>
<span class="sd">            number_of_subwords (int): number of subwords to split the word to</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: subwords</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">number_of_subwords</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[[</span><span class="n">word</span><span class="p">]]</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">all_binaries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cached</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">number_of_subwords</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">split_on_binary</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">binary</span><span class="p">)</span> <span class="k">for</span> <span class="n">binary</span> <span class="ow">in</span> <span class="n">all_binaries</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_tokenize_from_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">freq_dict</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Tokenize using the frequency dictionary </span>

<span class="sd">        Args:</span>
<span class="sd">            text (str): input string</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: generated tokens</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">freq_dict</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">output_tokens</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">freq_dict</span><span class="p">:</span>
                <span class="n">output_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">cache</span><span class="p">:</span>
                        <span class="n">groups_of_subwords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split_word_cached</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">groups_of_subwords</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split_word</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

                    <span class="c1"># filter out groups</span>
                    <span class="n">groups_of_valid_subwords</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                        <span class="nb">filter</span><span class="p">(</span>
                            <span class="k">lambda</span> <span class="n">group</span><span class="p">:</span> <span class="nb">all</span><span class="p">(</span>
                                <span class="n">subword</span> <span class="ow">in</span> <span class="n">freq_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">for</span> <span class="n">subword</span> <span class="ow">in</span> <span class="n">group</span>
                            <span class="p">),</span>
                            <span class="n">groups_of_subwords</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="n">groups_of_valid_subwords</span><span class="p">:</span>
                        <span class="k">break</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">groups_of_valid_subwords</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">output_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unk_token</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">sorted_groups_of_valid_subwords</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
                        <span class="n">groups_of_valid_subwords</span><span class="p">,</span>
                        <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">group</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">freq_dict</span><span class="p">[</span><span class="n">subword</span><span class="p">]</span> <span class="k">for</span> <span class="n">subword</span> <span class="ow">in</span> <span class="n">group</span><span class="p">),</span>
                    <span class="p">)</span>
                    <span class="n">tokens</span> <span class="o">=</span> <span class="n">sorted_groups_of_valid_subwords</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
                        <span class="n">output_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">token</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">output_tokens</span>

    <span class="k">def</span> <span class="nf">_truncate_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">freq_dict</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Truncate a frequency dictionary and add reserved tokens</span>

<span class="sd">        Args:</span>
<span class="sd">            freq_dict (dict): frequency dictionary</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: truncated dictionary based on the vocab size</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">sorted_tokens_frequency</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">freq_dict</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">}</span>

        <span class="n">limited_tokens_frequency</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">limited_tokens_frequency</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">unk_token</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">limited_tokens_frequency</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_token</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">limited_tokens_frequency</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">sorted_tokens_frequency</span><span class="o">.</span><span class="n">items</span><span class="p">())[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">]}</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">limited_tokens_frequency</span>

<div class="viewcode-block" id="BaseTokenizer.encode"><a class="viewcode-back" href="../../api/tkseem.tokenizers.BaseTokenizer.html#tkseem.tokenizers.BaseTokenizer.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert text to ids </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="BaseTokenizer.decode"><a class="viewcode-back" href="../../api/tkseem.tokenizers.BaseTokenizer.html#tkseem.tokenizers.BaseTokenizer.decode">[docs]</a>    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoded</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert ids to string</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="BaseTokenizer.tokenize"><a class="viewcode-back" href="../../api/tkseem.tokenizers.BaseTokenizer.html#tkseem.tokenizers.BaseTokenizer.tokenize">[docs]</a>    <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert text to tokens</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="BaseTokenizer.detokenize"><a class="viewcode-back" href="../../api/tkseem.tokenizers.BaseTokenizer.html#tkseem.tokenizers.BaseTokenizer.detokenize">[docs]</a>    <span class="k">def</span> <span class="nf">detokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Convert tokens to text</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="BaseTokenizer.encode_and_save"><a class="viewcode-back" href="../../api/tkseem.tokenizers.BaseTokenizer.html#tkseem.tokenizers.BaseTokenizer.encode_and_save">[docs]</a>    <span class="k">def</span> <span class="nf">encode_and_save</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Encode all the files then save as numpy</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;data/encoded&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">file_path</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">&quot;data/raw/&quot;</span><span class="p">):</span>
            <span class="n">ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;data/raw/</span><span class="si">{</span><span class="n">file_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
            <span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;data/encoded/</span><span class="si">{</span><span class="n">file_path</span><span class="p">[:</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span><span class="si">}</span><span class="s2">.npy&quot;</span><span class="p">,</span> <span class="n">ids</span><span class="p">)</span></div>

<div class="viewcode-block" id="BaseTokenizer.encode_sentences"><a class="viewcode-back" href="../../api/tkseem.tokenizers.BaseTokenizer.html#tkseem.tokenizers.BaseTokenizer.encode_sentences">[docs]</a>    <span class="k">def</span> <span class="nf">encode_sentences</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentences</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Encode a list of sentences using the trained model</span>

<span class="sd">        Args:</span>
<span class="sd">            sentences (list): list of sentences</span>
<span class="sd">            max_length (int, optional): specify the max length of encodings. Defaults to 100.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [np.array]: numpy array of encodings</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">encodings</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span>
            <span class="n">encoded</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_length</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">):</span>
                    <span class="n">current_token</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">current_token</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_token</span>
                <span class="n">encoded</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tokens_list</span><span class="p">()</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">current_token</span><span class="p">))</span>
            <span class="n">encodings</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">encodings</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="WordTokenizer"><a class="viewcode-back" href="../../api/tkseem.tokenizers.WordTokenizer.html#tkseem.tokenizers.WordTokenizer">[docs]</a><span class="k">class</span> <span class="nc">WordTokenizer</span><span class="p">(</span><span class="n">BaseTokenizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    White space based tokenization </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">tokens_frequency</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="WordTokenizer.train"><a class="viewcode-back" href="../../api/tkseem.tokenizers.WordTokenizer.html#tkseem.tokenizers.WordTokenizer.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">large_file</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train data using tokens&#39; frequency</span>

<span class="sd">        Args:</span>
<span class="sd">            large_file (bool, optional): Use memory mapping to read the datta quickly. Defaults to False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training WordTokenizer...&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">large_file</span><span class="p">:</span>
            <span class="n">sorted_tokens_frequency</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">k</span><span class="p">:</span> <span class="n">v</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_get_tokens_frequency_quickly</span><span class="p">(</span><span class="s2">&quot;data/raw/train.txt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span>
                    <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                    <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sorted_tokens_frequency</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">k</span><span class="p">:</span> <span class="n">v</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_get_tokens_frequency</span><span class="p">(</span><span class="s2">&quot;data/raw/train.txt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span>
                    <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                    <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">}</span>

        <span class="n">limited_tokens_frequency</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">limited_tokens_frequency</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">unk_token</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">limited_tokens_frequency</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_token</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">limited_tokens_frequency</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">sorted_tokens_frequency</span><span class="o">.</span><span class="n">items</span><span class="p">())[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">]}</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">limited_tokens_frequency</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordTokenizer.load_model"><a class="viewcode-back" href="../../api/tkseem.tokenizers.WordTokenizer.html#tkseem.tokenizers.WordTokenizer.load_model">[docs]</a>    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_path</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Load a saved model as a frequency dictionary</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): file path of the dictionary</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loading as pickle file ...&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">))</span></div>

<div class="viewcode-block" id="WordTokenizer.save_model"><a class="viewcode-back" href="../../api/tkseem.tokenizers.WordTokenizer.html#tkseem.tokenizers.WordTokenizer.save_model">[docs]</a>    <span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_path</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Save a model as a freqency dictionary</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): file path to save the model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">file_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">pickle_file</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Saving as pickle file ...&quot;</span><span class="p">)</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">,</span> <span class="n">pickle_file</span><span class="p">)</span></div>

<div class="viewcode-block" id="WordTokenizer.tokenize"><a class="viewcode-back" href="../../api/tkseem.tokenizers.WordTokenizer.html#tkseem.tokenizers.WordTokenizer.tokenize">[docs]</a>    <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Tokenize using the frequency dictionary </span>

<span class="sd">        Args:</span>
<span class="sd">            text (str): input string</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: generated tokens</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span>
        <span class="n">output_tokens</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">output_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unk_token</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output_tokens</span></div>

    <span class="c1"># Why do we have two versions of this method?</span>
    <span class="k">def</span> <span class="nf">_tokens_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Get tokens list</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: tokens </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<div class="viewcode-block" id="WordTokenizer.decode"><a class="viewcode-back" href="../../api/tkseem.tokenizers.WordTokenizer.html#tkseem.tokenizers.WordTokenizer.decode">[docs]</a>    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoded</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Decode ids</span>

<span class="sd">        Args:</span>
<span class="sd">            encoded (list): list of ids to decode</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: tokens</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">decoded</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_tokens_list</span><span class="p">()[</span><span class="nb">id</span><span class="p">]</span> <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="n">encoded</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">decoded</span></div>

<div class="viewcode-block" id="WordTokenizer.encode"><a class="viewcode-back" href="../../api/tkseem.tokenizers.WordTokenizer.html#tkseem.tokenizers.WordTokenizer.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Convert string to a list of ids</span>

<span class="sd">        Args:</span>
<span class="sd">            text (str): input string</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: list of ids</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_tokens_list</span><span class="p">()</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">encoded</span></div>

<div class="viewcode-block" id="WordTokenizer.detokenize"><a class="viewcode-back" href="../../api/tkseem.tokenizers.WordTokenizer.html#tkseem.tokenizers.WordTokenizer.detokenize">[docs]</a>    <span class="k">def</span> <span class="nf">detokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Convert tokens to a string</span>

<span class="sd">        Args:</span>
<span class="sd">            tokens (list): list of tokens</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: detokenized string</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">detokenized</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">detokenized</span></div></div>


<div class="viewcode-block" id="SentencePieceTokenizer"><a class="viewcode-back" href="../../api/tkseem.tokenizers.SentencePieceTokenizer.html#tkseem.tokenizers.SentencePieceTokenizer">[docs]</a><span class="k">class</span> <span class="nc">SentencePieceTokenizer</span><span class="p">(</span><span class="n">BaseTokenizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Sentencepiece based tokenization. </span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="SentencePieceTokenizer.train"><a class="viewcode-back" href="../../api/tkseem.tokenizers.SentencePieceTokenizer.html#tkseem.tokenizers.SentencePieceTokenizer.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;bpe&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Train using sentence piece</span>

<span class="sd">        Args:</span>
<span class="sd">            model_type (str, optional): train using sp. Defaults to &quot;bpe&quot;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training SentencePiece...&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">()</span>
        <span class="n">spm</span><span class="o">.</span><span class="n">SentencePieceTrainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
            <span class="nb">input</span><span class="o">=</span><span class="s2">&quot;data/raw/train.txt&quot;</span><span class="p">,</span>
            <span class="n">model_writer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">vocab_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
            <span class="n">model_type</span><span class="o">=</span><span class="n">model_type</span><span class="p">,</span>
            <span class="n">character_coverage</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
            <span class="n">unk_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">pad_id</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">bos_id</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">eos_id</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">normalization_rule_name</span><span class="o">=</span><span class="s2">&quot;identity&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s2">&quot;m.model&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sp</span> <span class="o">=</span> <span class="n">spm</span><span class="o">.</span><span class="n">SentencePieceProcessor</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s2">&quot;m.model&quot;</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sp</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">()</span></div>

<div class="viewcode-block" id="SentencePieceTokenizer.tokenize"><a class="viewcode-back" href="../../api/tkseem.tokenizers.SentencePieceTokenizer.html#tkseem.tokenizers.SentencePieceTokenizer.tokenize">[docs]</a>    <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Tokenize using the frequency dictionary </span>

<span class="sd">        Args:</span>
<span class="sd">            text (str): input string</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: generated tokens</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sp</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span></div>

<div class="viewcode-block" id="SentencePieceTokenizer.load_model"><a class="viewcode-back" href="../../api/tkseem.tokenizers.SentencePieceTokenizer.html#tkseem.tokenizers.SentencePieceTokenizer.load_model">[docs]</a>    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_path</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Load a saved sp model</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): file path of the trained model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">sp</span> <span class="o">=</span> <span class="n">spm</span><span class="o">.</span><span class="n">SentencePieceProcessor</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sp</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">Load</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span></div>

<div class="viewcode-block" id="SentencePieceTokenizer.save_model"><a class="viewcode-back" href="../../api/tkseem.tokenizers.SentencePieceTokenizer.html#tkseem.tokenizers.SentencePieceTokenizer.save_model">[docs]</a>    <span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_path</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Save a model as a freqency dictionary</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): file path to save the model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">getvalue</span><span class="p">())</span></div>

<div class="viewcode-block" id="SentencePieceTokenizer.encode"><a class="viewcode-back" href="../../api/tkseem.tokenizers.SentencePieceTokenizer.html#tkseem.tokenizers.SentencePieceTokenizer.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Convert string to a list of ids</span>

<span class="sd">        Args:</span>
<span class="sd">            text (str): input string</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: list of ids</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sp</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span></div>

<div class="viewcode-block" id="SentencePieceTokenizer.decode"><a class="viewcode-back" href="../../api/tkseem.tokenizers.SentencePieceTokenizer.html#tkseem.tokenizers.SentencePieceTokenizer.decode">[docs]</a>    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoded</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Decode ids</span>

<span class="sd">        Args:</span>
<span class="sd">            encoded (list): list of ids to decode</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: tokens</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sp</span><span class="o">.</span><span class="n">id_to_piece</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span></div>

<div class="viewcode-block" id="SentencePieceTokenizer.detokenize"><a class="viewcode-back" href="../../api/tkseem.tokenizers.SentencePieceTokenizer.html#tkseem.tokenizers.SentencePieceTokenizer.detokenize">[docs]</a>    <span class="k">def</span> <span class="nf">detokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Convert tokens to a string</span>

<span class="sd">        Args:</span>
<span class="sd">            tokens (list): list of tokens</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: detokenized string</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;▁&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="SentencePieceTokenizer.encode_sentences"><a class="viewcode-back" href="../../api/tkseem.tokenizers.SentencePieceTokenizer.html#tkseem.tokenizers.SentencePieceTokenizer.encode_sentences">[docs]</a>    <span class="k">def</span> <span class="nf">encode_sentences</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentences</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">20</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Encode a list of sentences using the trained model</span>

<span class="sd">        Args:</span>
<span class="sd">            sentences (list): list of sentences</span>
<span class="sd">            max_length (int, optional): specify the max length of encodings. Defaults to 100.</span>

<span class="sd">        Returns:</span>
<span class="sd">            [np.array]: list of encoded sentences</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">sparse_encodings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sp</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">out_type</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">encodings</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">encoding</span> <span class="ow">in</span> <span class="n">sparse_encodings</span><span class="p">:</span>
            <span class="n">curr_encoding</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_length</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoding</span><span class="p">):</span>
                    <span class="n">curr_encoding</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sp</span><span class="o">.</span><span class="n">pad_id</span><span class="p">())</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">curr_encoding</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">encoding</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">encodings</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curr_encoding</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">encodings</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="AutoTokenizer"><a class="viewcode-back" href="../../api/tkseem.tokenizers.AutoTokenizer.html#tkseem.tokenizers.AutoTokenizer">[docs]</a><span class="k">class</span> <span class="nc">AutoTokenizer</span><span class="p">(</span><span class="n">BaseTokenizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Auto tokenization using a saved dictionary </span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="AutoTokenizer.train"><a class="viewcode-back" href="../../api/tkseem.tokenizers.AutoTokenizer.html#tkseem.tokenizers.AutoTokenizer.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Use a default dictionary for training&quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training AutoTokenizer...&quot;</span><span class="p">)</span>
        <span class="n">vocab_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rel_path</span><span class="p">,</span> <span class="s1">&#39;dictionaries/vocab.pl&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_truncate_dict</span><span class="p">(</span><span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">vocab_path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)))</span></div>

<div class="viewcode-block" id="AutoTokenizer.tokenize"><a class="viewcode-back" href="../../api/tkseem.tokenizers.AutoTokenizer.html#tkseem.tokenizers.AutoTokenizer.tokenize">[docs]</a>    <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">cache</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Tokenize using the frequency dictionary </span>

<span class="sd">        Args:</span>
<span class="sd">            text (str): input string</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: generated tokens</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenize_from_dict</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">,</span> <span class="n">cache</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output_tokens</span></div>

    <span class="k">def</span> <span class="nf">_tokens_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Get tokens list</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: list of tokens.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<div class="viewcode-block" id="AutoTokenizer.decode"><a class="viewcode-back" href="../../api/tkseem.tokenizers.AutoTokenizer.html#tkseem.tokenizers.AutoTokenizer.decode">[docs]</a>    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoded</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Decode ids</span>

<span class="sd">        Args:</span>
<span class="sd">            encoded (list): list of ids to decode</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: tokens</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">decoded</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_tokens_list</span><span class="p">()[</span><span class="nb">id</span><span class="p">]</span> <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="n">encoded</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">decoded</span></div>

<div class="viewcode-block" id="AutoTokenizer.encode"><a class="viewcode-back" href="../../api/tkseem.tokenizers.AutoTokenizer.html#tkseem.tokenizers.AutoTokenizer.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Convert string to a list of ids</span>

<span class="sd">        Args:</span>
<span class="sd">            text (str): input string</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: list of ids</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_tokens_list</span><span class="p">()</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">encoded</span></div>

<div class="viewcode-block" id="AutoTokenizer.detokenize"><a class="viewcode-back" href="../../api/tkseem.tokenizers.AutoTokenizer.html#tkseem.tokenizers.AutoTokenizer.detokenize">[docs]</a>    <span class="k">def</span> <span class="nf">detokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Convert tokens to a string</span>

<span class="sd">        Args:</span>
<span class="sd">            tokens (list): list of tokens</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: detokenized string</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">detokenized</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;##&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">detokenized</span></div></div>


<div class="viewcode-block" id="RandomTokenizer"><a class="viewcode-back" href="../../api/tkseem.tokenizers.RandomTokenizer.html#tkseem.tokenizers.RandomTokenizer">[docs]</a><span class="k">class</span> <span class="nc">RandomTokenizer</span><span class="p">(</span><span class="n">BaseTokenizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Randomized based tokenization </span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="RandomTokenizer.train"><a class="viewcode-back" href="../../api/tkseem.tokenizers.RandomTokenizer.html#tkseem.tokenizers.RandomTokenizer.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Train data using randomly splitted subwords </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training RandomTokenizer ...&quot;</span><span class="p">)</span>
        <span class="n">text</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;data/raw/train.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_truncate_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_random_dict</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span></div>
 

    <span class="c1">##TODO too slow we need to speed up</span>
    <span class="k">def</span> <span class="nf">_random_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create dictionary based on random splitting</span>

<span class="sd">        Args:</span>
<span class="sd">            text (str): input text</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dict: tokens frequency</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">tokens_frequency</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">word</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="c1"># cached word splitting only accept words with max 20 length</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">20</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="c1"># random number of splits</span>
            <span class="n">groups</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split_word_cached</span><span class="p">(</span><span class="n">word</span><span class="o">.</span><span class="n">strip</span><span class="p">(),</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)))</span>
            <span class="n">groups</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">operator</span><span class="o">.</span><span class="n">iconcat</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="p">[])</span>

            <span class="k">for</span> <span class="n">sub_word</span> <span class="ow">in</span> <span class="n">groups</span><span class="p">:</span>
                <span class="n">tokens_frequency</span><span class="p">[</span><span class="n">sub_word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">tokens_frequency</span><span class="p">)</span>

<div class="viewcode-block" id="RandomTokenizer.tokenize"><a class="viewcode-back" href="../../api/tkseem.tokenizers.RandomTokenizer.html#tkseem.tokenizers.RandomTokenizer.tokenize">[docs]</a>    <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Tokenize using the frequency dictionary </span>

<span class="sd">        Args:</span>
<span class="sd">            text (str): input string</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: generated tokens</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenize_from_dict</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output_tokens</span></div>

<div class="viewcode-block" id="RandomTokenizer.load_model"><a class="viewcode-back" href="../../api/tkseem.tokenizers.RandomTokenizer.html#tkseem.tokenizers.RandomTokenizer.load_model">[docs]</a>    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_path</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Load a saved model as a frequency dictionary</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): file path of the dictionary</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loading as pickle file ...&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">))</span></div>

<div class="viewcode-block" id="RandomTokenizer.save_model"><a class="viewcode-back" href="../../api/tkseem.tokenizers.RandomTokenizer.html#tkseem.tokenizers.RandomTokenizer.save_model">[docs]</a>    <span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_path</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Save a model as a freqency dictionary</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): file path to save the model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">file_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">pickle_file</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Saving as pickle file ...&quot;</span><span class="p">)</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">,</span> <span class="n">pickle_file</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_tokens_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Get tokens list</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: list of tokens.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<div class="viewcode-block" id="RandomTokenizer.decode"><a class="viewcode-back" href="../../api/tkseem.tokenizers.RandomTokenizer.html#tkseem.tokenizers.RandomTokenizer.decode">[docs]</a>    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoded</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Decode ids</span>

<span class="sd">        Args:</span>
<span class="sd">            encoded (list): list of ids to decode</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: tokens</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">decoded</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_tokens_list</span><span class="p">()[</span><span class="nb">id</span><span class="p">]</span> <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="n">encoded</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">decoded</span></div>

<div class="viewcode-block" id="RandomTokenizer.encode"><a class="viewcode-back" href="../../api/tkseem.tokenizers.RandomTokenizer.html#tkseem.tokenizers.RandomTokenizer.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Convert string to a list of ids</span>

<span class="sd">        Args:</span>
<span class="sd">            text (str): input string</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: list of ids</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TOCKECK: Why not to put this in the base tokenizer as a default behaviour?</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_tokens_list</span><span class="p">()</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">encoded</span></div>

<div class="viewcode-block" id="RandomTokenizer.detokenize"><a class="viewcode-back" href="../../api/tkseem.tokenizers.RandomTokenizer.html#tkseem.tokenizers.RandomTokenizer.detokenize">[docs]</a>    <span class="k">def</span> <span class="nf">detokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Convert tokens to a string</span>

<span class="sd">        Args:</span>
<span class="sd">            tokens (list): list of tokens</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: detokenized string</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">detokenized</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;##&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">detokenized</span></div></div>


<div class="viewcode-block" id="DisjointLetterTokenizer"><a class="viewcode-back" href="../../api/tkseem.tokenizers.DisjointLetterTokenizer.html#tkseem.tokenizers.DisjointLetterTokenizer">[docs]</a><span class="k">class</span> <span class="nc">DisjointLetterTokenizer</span><span class="p">(</span><span class="n">BaseTokenizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Disjoint Letters based tokenization </span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="DisjointLetterTokenizer.train"><a class="viewcode-back" href="../../api/tkseem.tokenizers.DisjointLetterTokenizer.html#tkseem.tokenizers.DisjointLetterTokenizer.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Train data using disjoint letters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training DisjointLetterTokenizer ...&quot;</span><span class="p">)</span>
        <span class="n">rx</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;([اأإآءؤﻵﻹﻷدذرزو])&quot;</span><span class="p">)</span>

        <span class="n">text</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;data/raw/train.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">rx</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\1## &quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;## &quot;</span><span class="p">,</span> <span class="s2">&quot; ##&quot;</span><span class="p">)</span>
        
        <span class="n">tokens_frequency</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
            <span class="n">tokens_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_truncate_dict</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">tokens_frequency</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span></div>

<div class="viewcode-block" id="DisjointLetterTokenizer.tokenize"><a class="viewcode-back" href="../../api/tkseem.tokenizers.DisjointLetterTokenizer.html#tkseem.tokenizers.DisjointLetterTokenizer.tokenize">[docs]</a>    <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Tokenize using the frequency dictionary </span>

<span class="sd">        Args:</span>
<span class="sd">            text (str): input string</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: generated tokens</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tokenize_from_dict</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output_tokens</span></div>

<div class="viewcode-block" id="DisjointLetterTokenizer.load_model"><a class="viewcode-back" href="../../api/tkseem.tokenizers.DisjointLetterTokenizer.html#tkseem.tokenizers.DisjointLetterTokenizer.load_model">[docs]</a>    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_path</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Load a saved model as a frequency dictionary</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): file path of the dictionary</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loading as pickle file ...&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">))</span></div>

<div class="viewcode-block" id="DisjointLetterTokenizer.save_model"><a class="viewcode-back" href="../../api/tkseem.tokenizers.DisjointLetterTokenizer.html#tkseem.tokenizers.DisjointLetterTokenizer.save_model">[docs]</a>    <span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_path</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Save a model as a freqency dictionary</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): file path to save the model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">file_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">pickle_file</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Saving as pickle file ...&quot;</span><span class="p">)</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">,</span> <span class="n">pickle_file</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_tokens_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Get tokens list</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: list of tokens.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<div class="viewcode-block" id="DisjointLetterTokenizer.decode"><a class="viewcode-back" href="../../api/tkseem.tokenizers.DisjointLetterTokenizer.html#tkseem.tokenizers.DisjointLetterTokenizer.decode">[docs]</a>    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoded</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Decode ids</span>

<span class="sd">        Args:</span>
<span class="sd">            encoded (list): list of ids to decode</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: tokens</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">decoded</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_tokens_list</span><span class="p">()[</span><span class="nb">id</span><span class="p">]</span> <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="n">encoded</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">decoded</span></div>

<div class="viewcode-block" id="DisjointLetterTokenizer.encode"><a class="viewcode-back" href="../../api/tkseem.tokenizers.DisjointLetterTokenizer.html#tkseem.tokenizers.DisjointLetterTokenizer.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Convert string to a list of ids</span>

<span class="sd">        Args:</span>
<span class="sd">            text (str): input string</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: list of ids</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_tokens_list</span><span class="p">()</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">encoded</span></div>

<div class="viewcode-block" id="DisjointLetterTokenizer.detokenize"><a class="viewcode-back" href="../../api/tkseem.tokenizers.DisjointLetterTokenizer.html#tkseem.tokenizers.DisjointLetterTokenizer.detokenize">[docs]</a>    <span class="k">def</span> <span class="nf">detokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Convert tokens to a string</span>

<span class="sd">        Args:</span>
<span class="sd">            tokens (list): list of tokens</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: detokenized string</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">detokenized</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;##&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">detokenized</span></div></div>


<div class="viewcode-block" id="CharacterTokenizer"><a class="viewcode-back" href="../../api/tkseem.tokenizers.CharacterTokenizer.html#tkseem.tokenizers.CharacterTokenizer">[docs]</a><span class="k">class</span> <span class="nc">CharacterTokenizer</span><span class="p">(</span><span class="n">BaseTokenizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Character based tokenization </span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="CharacterTokenizer.train"><a class="viewcode-back" href="../../api/tkseem.tokenizers.CharacterTokenizer.html#tkseem.tokenizers.CharacterTokenizer.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Train data using characters </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training CharacterTokenizer ...&quot;</span><span class="p">)</span>
        <span class="n">rx</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\B(.)&quot;</span><span class="p">)</span>

        <span class="n">text</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;data/raw/train.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">rx</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot; ##\1&quot;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>

        <span class="n">tokens_frequency</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">):</span>
            <span class="n">tokens_frequency</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_truncate_dict</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">tokens_frequency</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span></div>

<div class="viewcode-block" id="CharacterTokenizer.tokenize"><a class="viewcode-back" href="../../api/tkseem.tokenizers.CharacterTokenizer.html#tkseem.tokenizers.CharacterTokenizer.tokenize">[docs]</a>    <span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Tokenize using the frequency dictionary </span>

<span class="sd">        Args:</span>
<span class="sd">            text (str): input string</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: generated tokens</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rx</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\B(.)&#39;</span><span class="p">)</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">rx</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39; ##\1&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
        <span class="n">output_tokens</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">:</span>
               <span class="n">output_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_token</span><span class="p">)</span> 
        <span class="k">return</span> <span class="n">output_tokens</span></div>

<div class="viewcode-block" id="CharacterTokenizer.load_model"><a class="viewcode-back" href="../../api/tkseem.tokenizers.CharacterTokenizer.html#tkseem.tokenizers.CharacterTokenizer.load_model">[docs]</a>    <span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_path</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Load a saved model as a frequency dictionary</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): file path of the dictionary</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loading as pickle file ...&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">))</span></div>

<div class="viewcode-block" id="CharacterTokenizer.save_model"><a class="viewcode-back" href="../../api/tkseem.tokenizers.CharacterTokenizer.html#tkseem.tokenizers.CharacterTokenizer.save_model">[docs]</a>    <span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_path</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Save a model as a freqency dictionary</span>

<span class="sd">        Args:</span>
<span class="sd">            file_path (str): file path to save the model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">file_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">pickle_file</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Saving as pickle file ...&quot;</span><span class="p">)</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="p">,</span> <span class="n">pickle_file</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_tokens_list</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Get tokens list</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: list of tokens.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<div class="viewcode-block" id="CharacterTokenizer.decode"><a class="viewcode-back" href="../../api/tkseem.tokenizers.CharacterTokenizer.html#tkseem.tokenizers.CharacterTokenizer.decode">[docs]</a>    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoded</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Decode ids</span>

<span class="sd">        Args:</span>
<span class="sd">            encoded (list): list of ids to decode</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: tokens</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">decoded</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_tokens_list</span><span class="p">()[</span><span class="nb">id</span><span class="p">]</span> <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="n">encoded</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">decoded</span></div>

<div class="viewcode-block" id="CharacterTokenizer.encode"><a class="viewcode-back" href="../../api/tkseem.tokenizers.CharacterTokenizer.html#tkseem.tokenizers.CharacterTokenizer.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Convert string to a list of ids</span>

<span class="sd">        Args:</span>
<span class="sd">            text (str): input string</span>

<span class="sd">        Returns:</span>
<span class="sd">            list: list of ids</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_tokens_list</span><span class="p">()</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">encoded</span></div>

<div class="viewcode-block" id="CharacterTokenizer.detokenize"><a class="viewcode-back" href="../../api/tkseem.tokenizers.CharacterTokenizer.html#tkseem.tokenizers.CharacterTokenizer.detokenize">[docs]</a>    <span class="k">def</span> <span class="nf">detokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Convert tokens to a string</span>

<span class="sd">        Args:</span>
<span class="sd">            tokens (list): list of tokens</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: detokenized string</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">detokenized</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;##&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">detokenized</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Zaid Alyafeai, Maged Saeed

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>